---
title: "p8105_hw5_sz2800"
author: "Stephanie Zhen"
date: "11/11/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
```

### Pre-Question 1:
```{r}
set.seed(10)

iris_with_missing = iris %>% 
  janitor::clean_names() %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(species = as.character(species))
```

## QUestion 1:
```{r}
iris_missing_na = function(x) {
  if (is.numeric(x)) {
    x = replace_na(x, mean(x, na.rm = TRUE))}
  else if (!is.numeric(x)){
    x = replace_na(x, "virginica")
  }
}

output_iris = map_df(iris_with_missing, iris_missing_na)
```

Imputation of missing numeric values:Missing numeric values are replaced with the mean of that variables.
Missing character values for the variable "species" are replaced with "virginica."

### Question 2:
```{r}
all_files = list.files(path = "./data") %>% 
  tibble::enframe(name = NULL) %>% 
  mutate(
    read_all_data = map(value, ~read_csv(str_c("./data/", .x)))
    ) %>% 
  unnest(read_all_data) %>% 
  separate(value, into = c("txt_group", "subject_id")) %>% 
  mutate(subject_id = str_c(txt_group, subject_id))
  
  files_tidy = pivot_longer(
    all_files,
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "sub_obs") %>%
    mutate(week = as.numeric(week))
  
knitr::kable(files_tidy,
             format = "html",
             digits = 3,
             caption = "Observation values with respect to Week")
```


```{r}
files_tidy_plot = ggplot(
  files_tidy, 
  aes(x = week, 
      y = sub_obs, 
      color = txt_group, 
      group = subject_id)) +
  geom_path() +
  labs(x = "Week", y = "Observed values", title = "Observations of Subjects over Time between Treatment Group", fill = "Treatment arm")

files_tidy_plot
```

The experimental arm has higher observed values than when compared to the control arm. SUbjects in the experimental arm also have a small increased in observed values over time, whereas there is no difference in observed value for the control group over time.  


### Question 3: Generating random samples
```{r}
set.seed(1)
prob3_sim_reg = function(n = 30, beta0 = 2, var = 50, beta1) {
  
  sim_data = tibble(
    x = rnorm(n, mean = 0, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, 0, var)
  )
  
  ls_sim = lm(y ~ x, data = sim_data) %>% 
    broom::tidy() %>% 
    filter(term == "x")
      
  tibble(
    beta1_hat = pull(ls_sim, estimate),
    p_value = pull(ls_sim, p.value)
  )
}
```


Iterating over beta1
```{r}
output_sim_reg = 
  tibble(beta1 = c(1, 2, 3, 4, 5, 6)) %>% 
  mutate(
    output_lists = map(.x = beta1, ~rerun(10000, prob3_sim_reg(beta1 = .x))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)

output_sim_reg

```


Proportion times the null was rejected
```{r}
ls_reject_pre = output_sim_reg %>%
  group_by(beta1) %>% 
  summarize(n = n(), 
            reject = sum(p_value <= 0.05), 
            non_reject = sum(p_value > 0.05), 
            prop_reject = (reject/n))

ls_reject_pre

ls_reject_hist = ls_reject_pre %>% 
  ggplot(aes(x = beta1, y = prop_reject)) +
  geom_histogram(stat = "identity") +
  labs(x = "Beta 1", y = "Proportion of Reject nulls", title = "Proportions of rejected null")

ls_reject_hist
```

THe effect size is the difference between the two means, estimated and null mean. When the null hypothesis is rejected, the differences between means are large, which results in a larger effect size. Power is the probability of rejecting the null correctly (null is not true and reject null). Therefore, the larger the effect size, the higher the statistical power. 


Average beta1 hat value vs average beta1 hat value of rejected null. 
```{r}
ls_beta_avg_pre = output_sim_reg %>%
  group_by(beta1) %>% 
  summarize(avg_beta_hat = mean(beta1_hat))

ls_beta_avg_pre

ls_bavg_rej_pre = output_sim_reg %>% 
  filter(p_value <= 0.05) %>% 
  group_by(beta1) %>%
  summarize(avg_betah_rej = mean(beta1_hat))

ls_bavg_rej_pre
```


```{r}
full = ls_beta_avg_pre %>%
  inner_join(ls_bavg_rej_pre, by = "beta1")

full

longer = full %>% 
  pivot_longer(
    avg_beta_hat:avg_betah_rej,
    names_to = "beta1_hat",
    values_to = "beta1_hat_value"
  )

knitr::kable(longer,
             format = "html",
             digits = 3,
             caption = "Avg Beta Hat vs Avg Beta hat reject values")
```

```{r}
ggplot(longer, aes(x = beta1, y = beta1_hat_value, color = beta1_hat, group = beta1_hat)) +
  geom_point() +
  geom_line() + 
  labs(x = "Beta 1", y = "Beta value", title = "Avg Beta Hat vs Avg Beta reject")
```


Judging solely on the graph, the average beta1_hat values in which the null hypothesis is different from the true beta value. This most likely result from the large variance of 50. A large variance indicates a large standard error. Therefore, the obtain a large test statistics (t = estimated beta1_hat / SE), in order to reject the p-value the estimated beta1_hat_reject value must also be large.    
